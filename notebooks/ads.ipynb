{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c055670-2298-46c3-a958-35fd4cdfee6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ads.common:Using 'resource_principal' authentication.\n",
      "{                                                                               \n",
      "    \"compartment_id\": \"ocid1.compartment.oc1..xxx\",\n",
      "    \"icon\": \"\",\n",
      "    \"id\": \"ocid1.datasciencemodel.oc1.ca-montreal-1.xx\",\n",
      "    \"is_fine_tuned_model\": false,\n",
      "    \"license\": \"\",\n",
      "    \"name\": \"custom-phind-codellama34bv2\",\n",
      "    \"organization\": \"\",\n",
      "    \"project_id\": \"ocid1.datascienceproject.oc1.ca-montreal-1.xx\",\n",
      "    \"tags\": {\n",
      "        \"Oracle-Tags\": {\n",
      "            \"CreatedBy\": \"ocid1.datasciencenotebooksession.oc1.ca-montreal-1.xxx\",\n",
      "            \"CreatedOn\": \"2024-07-18T09:19:09.466Z\"\n",
      "        },\n",
      "        \"aqua_custom_base_model\": \"true\",\n",
      "        \"OCI_AQUA\": \"active\",\n",
      "        \"ready_to_fine_tune\": \"true\"\n",
      "    },\n",
      "    \"task\": \"\",\n",
      "    \"time_created\": \"2024-07-18T09:19:09.554000+00:00\",\n",
      "    \"console_link\": [\n",
      "        \"https://cloud.oracle.com/data-science/models/ocid1.datasciencemodel.oc1.ca-montreal-1.xx?region=ca-montreal-1\"\n",
      "    ],\n",
      "    \"search_text\": \"{'CreatedBy': 'ocid1.datasciencenotebooksession.oc1.ca-montreal-1.xxx', 'CreatedOn': '2024-07-18T09:19:09.466Z'},true,active,true\",\n",
      "    \"ready_to_deploy\": true,\n",
      "    \"ready_to_finetune\": true,\n",
      "    \"ready_to_import\": false,\n",
      "    \"model_card\": \"---\\nlicense: llama2\\nmodel-index:\\n- name: Phind-CodeLlama-34B-v1\\n  results:\\n  - task:\\n      type: text-generation\\n    dataset:\\n      type: openai_humaneval\\n      name: HumanEval\\n    metrics:\\n    - name: pass@1\\n      type: pass@1\\n      value: 73.8%\\n      verified: false\\ntags:\\n- code llama\\n---\\n\\n# **Phind-CodeLlama-34B-v2**\\nWe've fine-tuned Phind-CodeLlama-34B-v1 on an additional 1.5B tokens high-quality programming-related data, achieving **73.8% pass@1** on HumanEval. It's the current state-of-the-art amongst open-source models.\\n\\nFurthermore, this model is **instruction-tuned** on the Alpaca/Vicuna format to be steerable and easy-to-use.\\n\\nMore details can be found on our [blog post](https://www.phind.com/blog/code-llama-beats-gpt4).\\n\\n## Model Details\\nThis model is fine-tuned from Phind-CodeLlama-34B-v1 and achieves **73.8% pass@1** on HumanEval.\\n\\nPhind-CodeLlama-34B-v2 is **multi-lingual** and is proficient in Python, C/C++, TypeScript, Java, and more.\\n\\n## Dataset Details\\nWe fined-tuned on a proprietary dataset of 1.5B tokens of high quality programming problems and solutions. This dataset consists of instruction-answer pairs instead of code completion examples, making it structurally different from HumanEval. LoRA was not used -- both models are a native finetune. We used DeepSpeed ZeRO 3 and Flash Attention 2 to train these models in 15 hours on 32 A100-80GB GPUs. We used a sequence length of 4096 tokens.\\n\\n## How to Get Started with the Model\\n\\nMake sure to install Transformers from the main git branch:\\n\\n```bash\\npip install git+https://github.com/huggingface/transformers.git\\n```\\n\\n## How to Prompt the Model\\nThis model accepts the Alpaca/Vicuna instruction format.\\n\\nFor example: \\n\\n```\\n### System Prompt\\nYou are an intelligent programming assistant.\\n\\n### User Message\\nImplement a linked list in C++\\n\\n### Assistant\\n...\\n```\\n\\n## How to reproduce HumanEval Results\\n\\nTo reproduce our results:\\n\\n```python\\n\\nfrom transformers import AutoTokenizer, LlamaForCausalLM\\nfrom human_eval.data import write_jsonl, read_problems\\nfrom tqdm import tqdm\\n\\n# initialize the model\\n\\nmodel_path = \\\"Phind/Phind-CodeLlama-34B-v2\\\"\\nmodel = LlamaForCausalLM.from_pretrained(model_path, device_map=\\\"auto\\\")\\ntokenizer = AutoTokenizer.from_pretrained(model_path)\\n\\n# HumanEval helper\\n\\ndef generate_one_completion(prompt: str):\\n    tokenizer.pad_token = tokenizer.eos_token\\n    inputs = tokenizer(prompt, return_tensors=\\\"pt\\\", truncation=True, max_length=4096)\\n\\n    # Generate\\n    generate_ids = model.generate(inputs.input_ids.to(\\\"cuda\\\"), max_new_tokens=384, do_sample=True, top_p=0.75, top_k=40, temperature=0.1)\\n    completion = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\\n    completion = completion.replace(prompt, \\\"\\\").split(\\\"\\\\n\\\\n\\\\n\\\")[0]\\n\\n    return completion\\n\\n# perform HumanEval\\nproblems = read_problems()\\n\\nnum_samples_per_task = 1\\nsamples = [\\n    dict(task_id=task_id, completion=generate_one_completion(problems[task_id][\\\"prompt\\\"]))\\n    for task_id in tqdm(problems)\\n    for _ in range(num_samples_per_task)\\n]\\nwrite_jsonl(\\\"samples.jsonl\\\", samples)\\n\\n# run `evaluate_functional_correctness samples.jsonl` in your HumanEval code sandbox\\n```\\n\\n## Bias, Risks, and Limitations\\n\\n<!-- This section is meant to convey both technical and sociotechnical limitations. -->\\nThis model has undergone very limited testing. Additional safety testing should be performed before any real-world deployments.\\n\\n\\n## Training details\\n\\n<!-- Total emissions (in grams of CO2eq) and additional considerations, such as electricity usage, go here. Edit the suggested text below accordingly -->\\n\\n- **Hardware Type:** 32x A100-80GB\\n- **Hours used:** 480 GPU-hours\\n- **Cloud Provider:** AWS\\n- **Compute Region:** us-east-1\",\n",
      "    \"inference_container\": \"odsc-vllm-serving\",\n",
      "    \"finetuning_container\": \"odsc-llm-fine-tuning\",\n",
      "    \"evaluation_container\": \"odsc-llm-evaluate\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ads aqua model get --model_id ocid1.datasciencemodel.oc1.ca-montreal-1.xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2065e80-60f9-4de8-9805-10daa9a70a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "!# ads aqua deployment create --model_id \"\" --instance_shape \"VM.GPU.A10.1\" --display_name \"falcon7b MD with Aqua CLI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90d81ee-b979-4818-9493-8fce01550175",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ads.common:Using 'resource_principal' authentication.\n",
      "{\n",
      "    \"id\": \"ocid1.datasciencemodel.oc1.ca-montreal-1.xx\",\n",
      "    \"name\": \"OCI_evaluation_20240718\",\n",
      "    \"console_url\": \"https://cloud.oracle.com/data-science/models/ocid1.datasciencemodel.oc1.ca-montreal-1.xx?region=ca-montreal-1\",\n",
      "    \"lifecycle_state\": \"SUCCEEDED\",\n",
      "    \"lifecycle_details\": \"Job run artifact execution succeeded. Infrastructure de-provisioning.\",\n",
      "    \"time_created\": \"2024-07-18T10:25:45.863000+00:00\",\n",
      "    \"tags\": {\n",
      "        \"Oracle-Tags\": {\n",
      "            \"CreatedBy\": \"ocid1.datasciencenotebooksession.oc1.ca-montreal-1.xxx\",\n",
      "            \"CreatedOn\": \"2024-07-18T10:25:45.764Z\"\n",
      "        },\n",
      "        \"aqua_evaluation\": \"aqua_evaluation\"\n",
      "    },\n",
      "    \"experiment\": {\n",
      "        \"id\": \"ocid1.datasciencemodelversionset.oc1.ca-montreal-1.xxx\",\n",
      "        \"name\": \"oci-sql-experiments\",\n",
      "        \"url\": \"https://cloud.oracle.com/data-science/model-version-sets/ocid1.datasciencemodelversionset.oc1.ca-montreal-1.amaaaaaafigrwqya6htwxsqqyedb2zhmm55dslh7jyju5jbqcwuwr2iairxa?region=ca-montreal-1\"\n",
      "    },\n",
      "    \"source\": {\n",
      "        \"id\": \"ocid1.datasciencemodeldeployment.oc1.ca-montreal-1.xxx\",\n",
      "        \"name\": \"modelDeployment_20240717\",\n",
      "        \"url\": \"https://cloud.oracle.com/data-science/model-deployments/ocid1.datasciencemodeldeployment.oc1.ca-montreal-1.amaaaaaafigrwqyavapmlw2mr637cw4gz3f5sudgvwzvln32tq53hlvmjrha?region=ca-montreal-1\"\n",
      "    },\n",
      "    \"job\": {\n",
      "        \"id\": \"ocid1.datasciencejobrun.oc1.ca-montreal-1.xxx\",\n",
      "        \"name\": \"OCI_evaluation_20240718\",\n",
      "        \"url\": \"https://cloud.oracle.com/data-science/job-runs/ocid1.datasciencejobrun.oc1.ca-montreal-1.xxx?region=ca-montreal-1\"\n",
      "    },\n",
      "    \"parameters\": {\n",
      "        \"max_tokens\": 500,\n",
      "        \"top_p\": 0.99,\n",
      "        \"top_k\": 50,\n",
      "        \"temperature\": 0.7,\n",
      "        \"presence_penalty\": 0,\n",
      "        \"frequency_penalty\": 0,\n",
      "        \"stop\": [],\n",
      "        \"shape\": \"VM.Standard.E3.Flex\",\n",
      "        \"dataset_path\": \"oci://genai-aqua-llms@ax6ymbvwiimc/evaluation-sample-no-sys-message.jsonl\",\n",
      "        \"report_path\": \"oci://genai-aqua-tuned@ax6ymbvwiimc/evaluation-phi2_v0simple\"\n",
      "    },\n",
      "    \"log_group\": {\n",
      "        \"id\": \"\",\n",
      "        \"name\": null,\n",
      "        \"url\": \"\"\n",
      "    },\n",
      "    \"log\": {\n",
      "        \"id\": \"\",\n",
      "        \"name\": null,\n",
      "        \"url\": \"\"\n",
      "    },\n",
      "    \"introspection\": {\n",
      "        \"aqua_evaluate\": {\n",
      "            \"evaluation_config\": {\n",
      "                \"key\": \"evaluation_config\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Validate evaluation config.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"evaluation_record\": {\n",
      "                \"key\": \"evaluation_record\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Verify the availability of the evaluation model catalog record.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"input_dataset_path\": {\n",
      "                \"key\": \"input_dataset_path\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Validate input dataset.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"output_report_path\": {\n",
      "                \"key\": \"output_report_path\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Verify output report path.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"evaluation_target\": {\n",
      "                \"key\": \"evaluation_target\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Confirm evaluation target availability.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"evaluation_compute\": {\n",
      "                \"key\": \"evaluation_compute\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Compute evaluation metrics.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            },\n",
      "            \"evaluation_report\": {\n",
      "                \"key\": \"evaluation_report\",\n",
      "                \"category\": \"aqua_evaluate\",\n",
      "                \"description\": \"Generate evaluation report.\",\n",
      "                \"error_msg\": \"\",\n",
      "                \"success\": true\n",
      "            }\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! ads aqua evaluation get --eval_id ocid1.datasciencemodel.oc1.ca-montreal-1.xxx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
