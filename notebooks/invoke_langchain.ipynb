!pip install langchain_community

#execute over langchain
import ads
from langchain_community.llms import OCIModelDeploymentVLLM
from string import Template

ads.set_auth("resource_principal")
model_endpoint="<MODEL ENDPOINT>"

llm = OCIModelDeploymentVLLM(
    endpoint=f"{model_endpoint}/predict",
    model="odsc-llm",
)

llm.invoke(
    input=Template(
        """"|begin_of_text|><|start_header_id|>user<|end_header_id|> $prompt <|eot_id|><|start_header_id|>assistant<|end_header_id|>"""
    ).substitute(
        prompt="What amateur radio bands are best to use when there are solar flares?"
    ),
    max_tokens=1000,
    temperature=0,
    p=0.9,
    #stop=["<|eot_id|>"],
    skip_special_tokens=False,
)