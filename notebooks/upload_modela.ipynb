{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eccded-fb6a-4f0d-80f9-80cbb8e3054e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HUGGINGFACE_TOKEN = \"XXXX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcad28d4-3d87-4ed8-86bf-fe1cf967297d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install huggingface-hub\n",
    "!huggingface-cli login --token $HUGGINGFACE_TOKEN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15717ee6-2988-4fd6-801d-30d56e212799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"Phind/Phind-CodeLlama-34B-v2\"\n",
    "model_prefix = \"phind_codellama34b\"\n",
    "bucket=\"genai-aqua-llms\"\n",
    "namespace = \"ax6ymbvwiimc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbfb5a9c-3206-45e4-9972-1928a158e68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/datascience/llms\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli download Phind/Phind-CodeLlama-34B-v2 --local-dir llms/${model_prefix} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16dfff-b7ee-4786-97b5-734c1e5e3985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d5e83f7-b485-4bfa-93a5-cd3d5196eea6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\t\t\t  pytorch_model-00005-of-00007.bin\n",
      "generation_config.json\t\t  pytorch_model-00006-of-00007.bin\n",
      "llama38b_instruct\t\t  pytorch_model-00007-of-00007.bin\n",
      "phind_codellama34b\t\t  pytorch_model.bin.index.json\n",
      "pytorch_model-00001-of-00007.bin  README.md\n",
      "pytorch_model-00002-of-00007.bin  special_tokens_map.json\n",
      "pytorch_model-00003-of-00007.bin  tokenizer_config.json\n",
      "pytorch_model-00004-of-00007.bin  tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "!ls llms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc27202-89b9-489e-a6e0-94bb0bf33d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lUploaded phind_codellama34bREADME.md  [####################################]  100%\n",
      "\u001b[?25lUploaded item  [####################################]  100%                       \n",
      "\n",
      "\u001b[?25lUploaded phind_codellama34bconfig.json  [####################################]  100%\n",
      "\u001b[?25lUploaded item  [####################################]  100%                         \n",
      "\n",
      "\u001b[?25lUploaded .gitignore  [####################################]  100%                   \n",
      "\u001b[?25lUploaded README.md.metadata  [####################################]  100%           \n",
      "\u001b[?25lUploaded .gitattributes.lock  [####################################]  100%          \n",
      "\u001b[?25lUploaded item  [####################################]  100%                         \n",
      "\n",
      "\n",
      "\n",
      "\u001b[?25lUploaded tokenizer_config.json.lock  [####################################]  100%   \n",
      "\u001b[?25lUploaded item  [####################################]  100%                         \n",
      "\n",
      "\n",
      "\u001b[?25lUploaded tokenizer.model.lock  [####################################]  100%         \n",
      "\u001b[?25lUploaded item  [####################################]  100%                         \n",
      "\n",
      "\n",
      "\n",
      "\u001b[?25lUploaded tokenizer.model.metadata  [####################################]  100%     \n",
      "\u001b[?25lUploaded tokenizer_config.json.metadata  [####################################]  100%\n",
      "\u001b[?25lUploaded item  [####################################]  100%                          \n",
      "\u001b[?25lUploaded generation_config.json.lock  [####################################]  100%   \n",
      "\u001b[?25lUploaded special_tokens_map.json.lock  [####################################]  100%  \n",
      "\n",
      "\n",
      "\u001b[?25lUploaded item  [####################################]  100%                          \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[?25lUploaded config.json.metadata  [####################################]  100%          \n",
      "\u001b[?25lUploaded item  [####################################]  100%                          \n",
      "\u001b[?25lUploaded item  [####################################]  100%                          \n",
      "\n",
      "\u001b[?25lUploaded generation_config.json.metadata  [####################################]  100%\n",
      "\u001b[?25lUploaded special_tokens_map.json  [####################################]  100%        \n",
      "\u001b[?25lUploaded model.safetensors.index.json  [####################################]  100%   \n",
      "\u001b[?25lUploaded README.md  [####################################]  100%                      \n",
      "\u001b[?25lUploaded LICENSE  [####################################]  100%                        \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded config.json  [####################################]  100%                    \n",
      "\u001b[?25lUploaded USE_POLICY.md  [####################################]  100%                  \n",
      "\u001b[?25lUploaded tokenizer_config.json  [####################################]  100%          \n",
      "\u001b[?25lUploaded generation_config.json  [####################################]  100%         \n",
      "\u001b[?25lUploaded .gitignore  [####################################]  100%                     \n",
      "\u001b[?25lUploaded tokenizer_config.json.lock  [####################################]  100%     \n",
      "\u001b[?25lUploaded .gitattributes.lock  [####################################]  100%            \n",
      "\u001b[?25lUploaded README.md.metadata  [####################################]  100%             \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\n",
      "\u001b[?25lUploaded tokenizer_config.json.metadata  [####################################]  100% \n",
      "\n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded .gitattributes  [####################################]  100%                 \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded tokenizer.json.lock  [####################################]  100%            \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\n",
      "\u001b[?25lUploaded generation_config.json.lock  [####################################]  100%    \n",
      "\u001b[?25lUploaded LICENSE.lock  [####################################]  100%                   \n",
      "\u001b[?25lUploaded tokenizer.json  [####################################]  100%                 \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded config.json.lock  [####################################]  100%               \n",
      "\n",
      "\u001b[?25lUploaded USE_POLICY.md.metadata  [####################################]  100%         \n",
      "\u001b[?25lUploaded .gitattributes.metadata  [####################################]  100%        \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded special_tokens_map.json.lock  [####################################]  100%   \n",
      "\u001b[?25lUploaded README.md.lock  [####################################]  100%                 \n",
      "\u001b[?25lUploaded config.json.metadata  [####################################]  100%           \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded tokenizer.json.metadata  [####################################]  100%        \n",
      "\u001b[?25lUploaded USE_POLICY.md.lock  [####################################]  100%             \n",
      "\u001b[?25lUploaded generation_config.json.metadata  [####################################]  100%\n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded consolidated.00.pth.lock  [####################################]  100%       \n",
      "\u001b[?25lUploaded tokenizer.model.lock  [####################################]  100%           \n",
      "\u001b[?25lUploaded params.json.metadata  [####################################]  100%           \n",
      "\u001b[?25lUploaded consolidated.00.pth.metadata  [####################################]  100%   \n",
      "\u001b[?25lUploaded tokenizer.model.metadata  [####################################]  100%       \n",
      "\u001b[?25lUploaded params.json.lock  [####################################]  100%               \n",
      "\u001b[?25lUploaded params.json  [####################################]  100%                    \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded README.md  [####################################]  100%                      \n",
      "\u001b[?25lUploaded special_tokens_map.json  [####################################]  100%        \n",
      "\u001b[?25lUploaded .gitattributes  [####################################]  100%                 \n",
      "\u001b[?25lUploaded tokenizer_config.json  [####################################]  100%          \n",
      "\u001b[?25lUploaded config.json  [####################################]  100%                    \n",
      "\u001b[?25lUploaded generation_config.json  [####################################]  100%         \n",
      "\u001b[?25lUploaded pytorch_model.bin.index.json  [####################################]  100%   \n",
      "\u001b[?25lUploaded tokenizer.model  [####################################]  100%                \n",
      "\u001b[?25lUploaded .gitattributes.lock  [####################################]  100%            \n",
      "\u001b[?25lUploaded .gitignore  [####################################]  100%                     \n",
      "\u001b[?25lUploaded README.md.metadata  [####################################]  100%             \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded tokenizer_config.json.lock  [####################################]  100%     \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded tokenizer.model  [####################################]  100%                \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\n",
      "\u001b[?25lUploaded tokenizer.model.lock  [####################################]  100%           \n",
      "\u001b[?25lUploaded tokenizer_config.json.metadata  [####################################]  100% \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded generation_config.json.lock  [####################################]  100%    \n",
      "\u001b[?25lUploaded item  [####################################]  100%                           \n",
      "\u001b[?25lUploaded tokenizer.model.metadata  [####################################]  100%       \n",
      "\u001b[?25lUploading parts for item  [#######################-------------]   66%  00:07:56      "
     ]
    }
   ],
   "source": [
    "!oci os object bulk-upload --src-dir llms/${model_prefix} --prefix $model_prefix -bn $bucket -ns $namespace --auth \"resource_principal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "005c7b90-a9df-4322-8a4b-b356b0a26b37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model_prefix=\"metallama38b_new\"\n",
    "bucket=\"genai-aqua-llms\"\n",
    "namespace=\"ax6ymbvwiimc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b070c3b0-7385-4ad5-9e4c-2db07b49f85e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/datascience/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token \"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\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e764d4-d5f8-42cc-ad0e-a834a41e96ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!huggingface-cli download meta-llama/Meta-Llama-3-8B-Instruct --local-dir models/${model_prefix} --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cb323-770f-4004-ae2b-e906553f26e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "!df -h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3b7c13-da9e-4612-850b-fe4ddc01a2cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!oci os object bulk-upload --src-dir llms/llama38b_instruct/ --prefix \"${model_prefix}-origin/\" -bn $bucket -ns $namespace --auth \"resource_principal\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
